"""
æ–°é—»èšåˆæœåŠ¡
æ•´åˆçˆ¬è™«ã€AIæ€»ç»“ã€ç¼“å­˜å’ŒæŒä¹…åŒ–
"""

from typing import List, Optional
from datetime import datetime
import asyncio

from core.models import Article, DailyBriefing
from adapters.factory import AdapterFactory
from repositories.news_repository import NewsRepository
from cache.cache_repository import CacheRepository


class NewsService:
    """æ–°é—»èšåˆæœåŠ¡ï¼ˆå®Œæ•´ç‰ˆï¼Œæ”¯æŒç¼“å­˜å’Œæ•°æ®åº“ï¼‰"""

    def __init__(self, ai_service, news_repo: NewsRepository = None, cache_repo: CacheRepository = None):
        self.adapter_factory = AdapterFactory()
        self.ai_service = ai_service
        self.news_repo = news_repo
        self.cache_repo = cache_repo

    async def generate_daily_briefing(
        self,
        date: Optional[str] = None,
        sources: Optional[List[str]] = None,
        limit: int = 10,
        use_cache: bool = True,
        save_to_db: bool = False
    ) -> DailyBriefing:
        """ç”Ÿæˆæ¯æ—¥æ—©æŠ¥"""
        date = date or datetime.now().strftime("%Y-%m-%d")
        sources = sources or ["aibase"]

        print(f"\nğŸ“¥ å¼€å§‹ç”Ÿæˆ {date} çš„æ—©æŠ¥...")

        # 1. æ£€æŸ¥ç¼“å­˜
        if use_cache and self.cache_repo:
            cached = await self.cache_repo.get_daily_briefing(date)
            if cached:
                print(f"âœ… ä»ç¼“å­˜è·å–æ—©æŠ¥")
                # ä»ç¼“å­˜çš„æ•°æ®æ¢å¤ DailyBriefing å¯¹è±¡
                articles = [Article(**a) for a in cached.get('articles', [])]
                return DailyBriefing(
                    id=cached.get('id'),
                    date=cached['date'],
                    title=cached['title'],
                    articles=articles,
                    total_count=cached['total_count'],
                    ai_summary=cached.get('ai_summary'),
                    created_at=datetime.fromisoformat(cached['created_at']) if cached.get('created_at') else None
                )

        # 2. ä»å¤šä¸ªæ¶ˆæ¯æºæŠ“å–æ–‡ç« 
        all_articles = []
        for source in sources:
            print(f"\nğŸ“ å¤„ç†æ¶ˆæ¯æº: {source}")
            adapter = self.adapter_factory.get_adapter(source)
            if adapter:
                urls = await adapter.fetch_article_list(limit)
                print(f"    æ‰¾åˆ° {len(urls)} ç¯‡æ–‡ç« ")

                for i, url in enumerate(urls, 1):
                    print(f"    [{i}/{len(urls)}] æ­£åœ¨è·å–: {url}", end=" ")
                    article = await adapter.fetch_article(url)
                    if article:
                        print(f"âœ… {article.title[:30]}...")
                        all_articles.append(article)
                    else:
                        print(f"âŒ")

        if not all_articles:
            print("âš ï¸ æœªè·å–åˆ°ä»»ä½•æ–‡ç« ")
            return DailyBriefing(
                date=date,
                title=f"æ—©æŠ¥ - {date}",
                articles=[],
                total_count=0
            )

        # 3. ç”ŸæˆAIæ€»ç»“
        print(f"\nğŸ¤– å¼€å§‹ç”ŸæˆAIæ€»ç»“...")
        articles_with_summary = await self.ai_service.batch_generate_summaries(all_articles)
        success_count = sum(1 for a in articles_with_summary if a.summary)
        print(f"    âœ… æˆåŠŸç”Ÿæˆ {success_count}/{len(articles_with_summary)} ç¯‡æ–‡ç« æ€»ç»“")

        # 4. ç”Ÿæˆæ•´ä½“æ€»ç»“
        daily_summary = await self.ai_service.generate_daily_summary(articles_with_summary)
        if daily_summary:
            print(f"    âœ… æ¯æ—¥æ±‡æ€»: {daily_summary}")

        # 5. æ„å»ºæ—©æŠ¥å¯¹è±¡
        briefing = DailyBriefing(
            date=date,
            title=f"æ—©æŠ¥ - {date}",
            articles=articles_with_summary,
            total_count=len(articles_with_summary),
            ai_summary=daily_summary
        )

        # 6. æŒä¹…åŒ–åˆ°æ•°æ®åº“
        if save_to_db and self.news_repo:
            print(f"\nğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
            briefing_id = self.news_repo.save_daily_briefing(briefing)
            briefing.id = briefing_id
            print(f"    âœ… å·²ä¿å­˜ï¼ˆID: {briefing_id}ï¼‰")

        # 7. å†™å…¥ç¼“å­˜
        if use_cache and self.cache_repo:
            await self.cache_repo.set_daily_briefing(date, briefing.to_dict())
            await self.cache_repo.set_latest_briefing(briefing.to_dict())
            print(f"    âœ… å·²ç¼“å­˜")

        return briefing

    async def get_briefing_by_date(self, date: str) -> Optional[DailyBriefing]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„æ—©æŠ¥"""
        # å…ˆæŸ¥ç¼“å­˜
        if self.cache_repo:
            cached = await self.cache_repo.get_daily_briefing(date)
            if cached:
                articles = [Article(**a) for a in cached.get('articles', [])]
                return DailyBriefing(
                    id=cached.get('id'),
                    date=cached['date'],
                    title=cached['title'],
                    articles=articles,
                    total_count=cached['total_count'],
                    ai_summary=cached.get('ai_summary'),
                    created_at=datetime.fromisoformat(cached['created_at']) if cached.get('created_at') else None
                )

        # æŸ¥æ•°æ®åº“
        if self.news_repo:
            briefing_data = self.news_repo.get_daily_briefing(date)
            if briefing_data:
                articles = [Article(**a) for a in briefing_data.get('articles', [])]
                return DailyBriefing(
                    id=briefing_data.get('id'),
                    date=briefing_data['date'],
                    title=briefing_data['title'],
                    articles=articles,
                    total_count=briefing_data['total_count'],
                    ai_summary=briefing_data.get('ai_summary'),
                    created_at=datetime.fromisoformat(briefing_data['created_at']) if briefing_data.get('created_at') else None
                )

        return None

    async def get_latest_briefing(self) -> Optional[DailyBriefing]:
        """è·å–æœ€æ–°æ—©æŠ¥"""
        # å…ˆæŸ¥ç¼“å­˜
        if self.cache_repo:
            cached = await self.cache_repo.get_latest_briefing()
            if cached:
                articles = [Article(**a) for a in cached.get('articles', [])]
                return DailyBriefing(
                    id=cached.get('id'),
                    date=cached['date'],
                    title=cached['title'],
                    articles=articles,
                    total_count=cached['total_count'],
                    ai_summary=cached.get('ai_summary'),
                    created_at=datetime.fromisoformat(cached['created_at']) if cached.get('created_at') else None
                )

        # æŸ¥æ•°æ®åº“
        if self.news_repo:
            briefing_data = self.news_repo.get_latest_briefing()
            if briefing_data:
                articles = [Article(**a) for a in briefing_data.get('articles', [])]
                return DailyBriefing(
                    id=briefing_data.get('id'),
                    date=briefing_data['date'],
                    title=briefing_data['title'],
                    articles=articles,
                    total_count=briefing_data['total_count'],
                    ai_summary=briefing_data.get('ai_summary'),
                    created_at=datetime.fromisoformat(briefing_data['created_at']) if briefing_data.get('created_at') else None
                )

        return None

    def save_briefing_to_json(self, briefing: DailyBriefing, filename: str = "articles_data.json"):
        """ä¿å­˜æ—©æŠ¥åˆ°JSONæ–‡ä»¶"""
        import json
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(briefing.to_dict(), f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°: {filename}")
