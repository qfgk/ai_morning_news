"""
æ—©æŠ¥ç³»ç»Ÿè¿è¡Œè„šæœ¬
æ”¯æŒç¼“å­˜å’Œæ•°æ®åº“åŠŸèƒ½
"""

import asyncio
import os
import sys
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from services.news_service import NewsService
from services.ai_summary_service import AISummaryService
from repositories.news_repository import NewsRepository
from cache.cache_repository import CacheRepository
from cache.redis_client import RedisClient
from config.settings import get_settings, get_ai_settings


async def main():
    """ä¸»å‡½æ•°"""
    settings = get_settings()

    print("=" * 60)
    print(f"ğŸš€ {settings.APP_NAME} v{settings.APP_VERSION}")
    print("=" * 60)

    # è·å– AI é…ç½®
    try:
        api_key, base_url, model = get_ai_settings()
        print(f"\nğŸ¤– AI é…ç½®:")
        print(f"   API: {base_url}")
        print(f"   æ¨¡å‹: {model}")
    except ValueError as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® AI_API_KEY")
        print("   å¯ä»¥å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å…¥ä½ çš„APIå¯†é’¥")
        return

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    use_cache = "--no-cache" not in sys.argv
    use_db = "--db" in sys.argv
    use_redis = "--redis" in sys.argv

    print(f"\nğŸ“‹ è¿è¡Œæ¨¡å¼:")
    print(f"   ç¼“å­˜: {'âœ…' if use_cache else 'âŒ'}")
    print(f"   æ•°æ®åº“: {'âœ…' if use_db else 'âŒ'}")
    print(f"   Redis: {'âœ…' if use_redis else 'âŒ'}")

    # åˆå§‹åŒ– AI æœåŠ¡
    ai_service = AISummaryService(
        api_key=api_key,
        base_url=base_url,
        model=model,
        max_concurrent=settings.AI_SUMMARY_CONCURRENT
    )

    news_repo = None
    if use_db:
        print(f"\nğŸ’¾ åˆå§‹åŒ–æ•°æ®åº“...")
        try:
            news_repo = NewsRepository()
            print(f"   âœ… æ•°æ®åº“å·²è¿æ¥")
        except Exception as e:
            print(f"   âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            print(f"   æç¤º: è¯·å…ˆè¿è¡Œ 'python scripts/init_db.py' åˆå§‹åŒ–æ•°æ®åº“")
            use_db = False

    cache_repo = None
    if use_redis:
        print(f"\nğŸ”„ åˆå§‹åŒ–Redis...")
        try:
            redis_client = RedisClient(
                host=settings.REDIS_HOST,
                port=settings.REDIS_PORT,
                password=settings.REDIS_PASSWORD,
                db=settings.REDIS_DB
            )
            await redis_client.connect()
            if await redis_client.ping():
                cache_repo = CacheRepository(redis_client)
                print(f"   âœ… Rediså·²è¿æ¥")
            else:
                print(f"   âŒ Redisè¿æ¥å¤±è´¥")
                await redis_client.disconnect()
        except Exception as e:
            print(f"   âŒ Redisè¿æ¥å¤±è´¥: {e}")
            print(f"   æç¤º: è¯·ç¡®ä¿RedisæœåŠ¡å·²å¯åŠ¨")

    # åˆ›å»ºæ–°é—»æœåŠ¡
    news_service = NewsService(
        ai_service=ai_service,
        news_repo=news_repo,
        cache_repo=cache_repo
    )

    # ç”Ÿæˆæ—©æŠ¥
    briefing = await news_service.generate_daily_briefing(
        sources=["aibase"],
        limit=settings.CRAWLER_MAX_ARTICLES,
        use_cache=use_cache,
        save_to_db=use_db
    )

    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 60)
    print(f"ğŸ“° {briefing.title}")
    print("=" * 60)

    if briefing.articles:
        print(f"\nâœ… å…±è·å– {briefing.total_count} ç¯‡æ–‡ç« \n")

        for i, article in enumerate(briefing.articles, 1):
            print(f"{i}. {article.title}")
            if article.summary:
                print(f"   {article.summary}")
            print()

        if briefing.ai_summary:
            print("ğŸ“ æ¯æ—¥æ±‡æ€»:")
            print(f"   {briefing.ai_summary}\n")

        # ä¿å­˜åˆ°JSON
        news_service.save_briefing_to_json(briefing)

        print("=" * 60)
        print("âœ… æ—©æŠ¥ç”Ÿæˆå®Œæˆï¼")
        print("=" * 60)
    else:
        print("âš ï¸ æœªè·å–åˆ°ä»»ä½•æ–‡ç« ")

    # å…³é—­Redisè¿æ¥
    if cache_repo and cache_repo.redis:
        await cache_repo.redis.disconnect()


if __name__ == "__main__":
    asyncio.run(main())
